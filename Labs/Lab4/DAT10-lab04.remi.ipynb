{
 "metadata": {
  "name": "",
  "signature": "sha256:3543ae9d4e4af07a7bd0f19387d41f2ccadffcac4c40bf93b4eace97a739e64e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# GA Data Science 10 (DAT10) - Lab4\n",
      "\n",
      "### KNN, Matplotlib\n",
      "\n",
      "Craig Sakuma"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Last Time:\n",
      "\n",
      "- #### Numpy\n",
      "- #### Pandas\n",
      "- #### Kimono Labs API\n",
      "\n",
      "#### Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Agenda\n",
      "\n",
      "1. Matplotlib\n",
      "2. KNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. Matplotlib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# where do we find Machine Learning algorithms in python?\n",
      "\n",
      "# sklearn\n",
      "# http://scikit-learn.org/stable/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make things simple, load a default dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from the datasets load the iris data into a variable called iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does the iris data set look like"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(iris)\n",
      "iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "{'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
        " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "        [ 4.9,  3. ,  1.4,  0.2],\n",
        "        [ 4.7,  3.2,  1.3,  0.2],\n",
        "        [ 4.6,  3.1,  1.5,  0.2],\n",
        "        [ 5. ,  3.6,  1.4,  0.2],\n",
        "        [ 5.4,  3.9,  1.7,  0.4],\n",
        "        [ 4.6,  3.4,  1.4,  0.3],\n",
        "        [ 5. ,  3.4,  1.5,  0.2],\n",
        "        [ 4.4,  2.9,  1.4,  0.2],\n",
        "        [ 4.9,  3.1,  1.5,  0.1],\n",
        "        [ 5.4,  3.7,  1.5,  0.2],\n",
        "        [ 4.8,  3.4,  1.6,  0.2],\n",
        "        [ 4.8,  3. ,  1.4,  0.1],\n",
        "        [ 4.3,  3. ,  1.1,  0.1],\n",
        "        [ 5.8,  4. ,  1.2,  0.2],\n",
        "        [ 5.7,  4.4,  1.5,  0.4],\n",
        "        [ 5.4,  3.9,  1.3,  0.4],\n",
        "        [ 5.1,  3.5,  1.4,  0.3],\n",
        "        [ 5.7,  3.8,  1.7,  0.3],\n",
        "        [ 5.1,  3.8,  1.5,  0.3],\n",
        "        [ 5.4,  3.4,  1.7,  0.2],\n",
        "        [ 5.1,  3.7,  1.5,  0.4],\n",
        "        [ 4.6,  3.6,  1. ,  0.2],\n",
        "        [ 5.1,  3.3,  1.7,  0.5],\n",
        "        [ 4.8,  3.4,  1.9,  0.2],\n",
        "        [ 5. ,  3. ,  1.6,  0.2],\n",
        "        [ 5. ,  3.4,  1.6,  0.4],\n",
        "        [ 5.2,  3.5,  1.5,  0.2],\n",
        "        [ 5.2,  3.4,  1.4,  0.2],\n",
        "        [ 4.7,  3.2,  1.6,  0.2],\n",
        "        [ 4.8,  3.1,  1.6,  0.2],\n",
        "        [ 5.4,  3.4,  1.5,  0.4],\n",
        "        [ 5.2,  4.1,  1.5,  0.1],\n",
        "        [ 5.5,  4.2,  1.4,  0.2],\n",
        "        [ 4.9,  3.1,  1.5,  0.1],\n",
        "        [ 5. ,  3.2,  1.2,  0.2],\n",
        "        [ 5.5,  3.5,  1.3,  0.2],\n",
        "        [ 4.9,  3.1,  1.5,  0.1],\n",
        "        [ 4.4,  3. ,  1.3,  0.2],\n",
        "        [ 5.1,  3.4,  1.5,  0.2],\n",
        "        [ 5. ,  3.5,  1.3,  0.3],\n",
        "        [ 4.5,  2.3,  1.3,  0.3],\n",
        "        [ 4.4,  3.2,  1.3,  0.2],\n",
        "        [ 5. ,  3.5,  1.6,  0.6],\n",
        "        [ 5.1,  3.8,  1.9,  0.4],\n",
        "        [ 4.8,  3. ,  1.4,  0.3],\n",
        "        [ 5.1,  3.8,  1.6,  0.2],\n",
        "        [ 4.6,  3.2,  1.4,  0.2],\n",
        "        [ 5.3,  3.7,  1.5,  0.2],\n",
        "        [ 5. ,  3.3,  1.4,  0.2],\n",
        "        [ 7. ,  3.2,  4.7,  1.4],\n",
        "        [ 6.4,  3.2,  4.5,  1.5],\n",
        "        [ 6.9,  3.1,  4.9,  1.5],\n",
        "        [ 5.5,  2.3,  4. ,  1.3],\n",
        "        [ 6.5,  2.8,  4.6,  1.5],\n",
        "        [ 5.7,  2.8,  4.5,  1.3],\n",
        "        [ 6.3,  3.3,  4.7,  1.6],\n",
        "        [ 4.9,  2.4,  3.3,  1. ],\n",
        "        [ 6.6,  2.9,  4.6,  1.3],\n",
        "        [ 5.2,  2.7,  3.9,  1.4],\n",
        "        [ 5. ,  2. ,  3.5,  1. ],\n",
        "        [ 5.9,  3. ,  4.2,  1.5],\n",
        "        [ 6. ,  2.2,  4. ,  1. ],\n",
        "        [ 6.1,  2.9,  4.7,  1.4],\n",
        "        [ 5.6,  2.9,  3.6,  1.3],\n",
        "        [ 6.7,  3.1,  4.4,  1.4],\n",
        "        [ 5.6,  3. ,  4.5,  1.5],\n",
        "        [ 5.8,  2.7,  4.1,  1. ],\n",
        "        [ 6.2,  2.2,  4.5,  1.5],\n",
        "        [ 5.6,  2.5,  3.9,  1.1],\n",
        "        [ 5.9,  3.2,  4.8,  1.8],\n",
        "        [ 6.1,  2.8,  4. ,  1.3],\n",
        "        [ 6.3,  2.5,  4.9,  1.5],\n",
        "        [ 6.1,  2.8,  4.7,  1.2],\n",
        "        [ 6.4,  2.9,  4.3,  1.3],\n",
        "        [ 6.6,  3. ,  4.4,  1.4],\n",
        "        [ 6.8,  2.8,  4.8,  1.4],\n",
        "        [ 6.7,  3. ,  5. ,  1.7],\n",
        "        [ 6. ,  2.9,  4.5,  1.5],\n",
        "        [ 5.7,  2.6,  3.5,  1. ],\n",
        "        [ 5.5,  2.4,  3.8,  1.1],\n",
        "        [ 5.5,  2.4,  3.7,  1. ],\n",
        "        [ 5.8,  2.7,  3.9,  1.2],\n",
        "        [ 6. ,  2.7,  5.1,  1.6],\n",
        "        [ 5.4,  3. ,  4.5,  1.5],\n",
        "        [ 6. ,  3.4,  4.5,  1.6],\n",
        "        [ 6.7,  3.1,  4.7,  1.5],\n",
        "        [ 6.3,  2.3,  4.4,  1.3],\n",
        "        [ 5.6,  3. ,  4.1,  1.3],\n",
        "        [ 5.5,  2.5,  4. ,  1.3],\n",
        "        [ 5.5,  2.6,  4.4,  1.2],\n",
        "        [ 6.1,  3. ,  4.6,  1.4],\n",
        "        [ 5.8,  2.6,  4. ,  1.2],\n",
        "        [ 5. ,  2.3,  3.3,  1. ],\n",
        "        [ 5.6,  2.7,  4.2,  1.3],\n",
        "        [ 5.7,  3. ,  4.2,  1.2],\n",
        "        [ 5.7,  2.9,  4.2,  1.3],\n",
        "        [ 6.2,  2.9,  4.3,  1.3],\n",
        "        [ 5.1,  2.5,  3. ,  1.1],\n",
        "        [ 5.7,  2.8,  4.1,  1.3],\n",
        "        [ 6.3,  3.3,  6. ,  2.5],\n",
        "        [ 5.8,  2.7,  5.1,  1.9],\n",
        "        [ 7.1,  3. ,  5.9,  2.1],\n",
        "        [ 6.3,  2.9,  5.6,  1.8],\n",
        "        [ 6.5,  3. ,  5.8,  2.2],\n",
        "        [ 7.6,  3. ,  6.6,  2.1],\n",
        "        [ 4.9,  2.5,  4.5,  1.7],\n",
        "        [ 7.3,  2.9,  6.3,  1.8],\n",
        "        [ 6.7,  2.5,  5.8,  1.8],\n",
        "        [ 7.2,  3.6,  6.1,  2.5],\n",
        "        [ 6.5,  3.2,  5.1,  2. ],\n",
        "        [ 6.4,  2.7,  5.3,  1.9],\n",
        "        [ 6.8,  3. ,  5.5,  2.1],\n",
        "        [ 5.7,  2.5,  5. ,  2. ],\n",
        "        [ 5.8,  2.8,  5.1,  2.4],\n",
        "        [ 6.4,  3.2,  5.3,  2.3],\n",
        "        [ 6.5,  3. ,  5.5,  1.8],\n",
        "        [ 7.7,  3.8,  6.7,  2.2],\n",
        "        [ 7.7,  2.6,  6.9,  2.3],\n",
        "        [ 6. ,  2.2,  5. ,  1.5],\n",
        "        [ 6.9,  3.2,  5.7,  2.3],\n",
        "        [ 5.6,  2.8,  4.9,  2. ],\n",
        "        [ 7.7,  2.8,  6.7,  2. ],\n",
        "        [ 6.3,  2.7,  4.9,  1.8],\n",
        "        [ 6.7,  3.3,  5.7,  2.1],\n",
        "        [ 7.2,  3.2,  6. ,  1.8],\n",
        "        [ 6.2,  2.8,  4.8,  1.8],\n",
        "        [ 6.1,  3. ,  4.9,  1.8],\n",
        "        [ 6.4,  2.8,  5.6,  2.1],\n",
        "        [ 7.2,  3. ,  5.8,  1.6],\n",
        "        [ 7.4,  2.8,  6.1,  1.9],\n",
        "        [ 7.9,  3.8,  6.4,  2. ],\n",
        "        [ 6.4,  2.8,  5.6,  2.2],\n",
        "        [ 6.3,  2.8,  5.1,  1.5],\n",
        "        [ 6.1,  2.6,  5.6,  1.4],\n",
        "        [ 7.7,  3. ,  6.1,  2.3],\n",
        "        [ 6.3,  3.4,  5.6,  2.4],\n",
        "        [ 6.4,  3.1,  5.5,  1.8],\n",
        "        [ 6. ,  3. ,  4.8,  1.8],\n",
        "        [ 6.9,  3.1,  5.4,  2.1],\n",
        "        [ 6.7,  3.1,  5.6,  2.4],\n",
        "        [ 6.9,  3.1,  5.1,  2.3],\n",
        "        [ 5.8,  2.7,  5.1,  1.9],\n",
        "        [ 6.8,  3.2,  5.9,  2.3],\n",
        "        [ 6.7,  3.3,  5.7,  2.5],\n",
        "        [ 6.7,  3. ,  5.2,  2.3],\n",
        "        [ 6.3,  2.5,  5. ,  1.9],\n",
        "        [ 6.5,  3. ,  5.2,  2. ],\n",
        "        [ 6.2,  3.4,  5.4,  2.3],\n",
        "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
        " 'feature_names': ['sepal length (cm)',\n",
        "  'sepal width (cm)',\n",
        "  'petal length (cm)',\n",
        "  'petal width (cm)'],\n",
        " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
        " 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
        "       dtype='|S10')}"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "['target_names', 'data', 'target', 'DESCR', 'feature_names']"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris['DESCR']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iris Plants Database\n",
        "\n",
        "Notes\n",
        "-----\n",
        "Data Set Characteristics:\n",
        "    :Number of Instances: 150 (50 in each of three classes)\n",
        "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
        "    :Attribute Information:\n",
        "        - sepal length in cm\n",
        "        - sepal width in cm\n",
        "        - petal length in cm\n",
        "        - petal width in cm\n",
        "        - class:\n",
        "                - Iris-Setosa\n",
        "                - Iris-Versicolour\n",
        "                - Iris-Virginica\n",
        "    :Summary Statistics:\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "                    Min  Max   Mean    SD   Class Correlation\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
        "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
        "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
        "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    :Missing Attribute Values: None\n",
        "    :Class Distribution: 33.3% for each of 3 classes.\n",
        "    :Creator: R.A. Fisher\n",
        "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
        "    :Date: July, 1988\n",
        "\n",
        "This is a copy of UCI ML iris datasets.\n",
        "http://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "The famous Iris database, first used by Sir R.A Fisher\n",
        "\n",
        "This is perhaps the best known database to be found in the\n",
        "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
        "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
        "data set contains 3 classes of 50 instances each, where each class refers to a\n",
        "type of iris plant.  One class is linearly separable from the other 2; the\n",
        "latter are NOT linearly separable from each other.\n",
        "\n",
        "References\n",
        "----------\n",
        "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
        "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
        "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
        "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
        "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
        "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
        "     Structure and Classification Rule for Recognition in Partially Exposed\n",
        "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
        "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
        "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
        "     on Information Theory, May 1972, 431-433.\n",
        "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
        "     conceptual clustering system finds 3 classes in the data.\n",
        "   - Many, many more ...\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lets display that data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "from matplotlib.ticker import FormatStrFormatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data with load_iris from sklearn\n",
      "X = iris['data']\n",
      "Names = iris['feature_names']\n",
      "y = iris['target']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate the top-level figure for this plotting exercise\n",
      "fig = plt.figure(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate our six subplots. Note that context will be set to the last one by default.\n",
      "ax1 = fig.add_subplot(2,3,1)\n",
      "ax2 = fig.add_subplot(2,3,2)\n",
      "ax3 = fig.add_subplot(2,3,3)\n",
      "ax4 = fig.add_subplot(2,3,4)\n",
      "ax5 = fig.add_subplot(2,3,5)\n",
      "ax6 = fig.add_subplot(2,3,6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Title our figure. This is a different command than titling an individual subplot.\n",
      "fig.suptitle('Subplots demo with Iris Data', fontsize=14)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "<matplotlib.text.Text at 0x1168b10d0>"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the number of decimal places in our y-axis tick labels\n",
      "majorFormatter = FormatStrFormatter('%1.1f')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "majorFormatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "<matplotlib.ticker.FormatStrFormatter at 0x1168b1210>"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop through our subplots and set font sizes\n",
      "# HINT: plt.gcf().axes gets all the axes for our current figure\n",
      "all_axes = plt.gcf().axes\n",
      "for ax in all_axes:\n",
      "    ax.yaxis.set_major_formatter(majorFormatter)\n",
      "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
      "        ticklabel.set_fontsize(6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format first subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    # We plot each class on its own to get different colored markers\n",
      "    ax1.scatter(X[y == t,0],\n",
      "                X[y == t,1],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax1.set_xlabel(Names[0], fontsize=8)\n",
      "    ax1.set_ylabel(Names[1], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Zip Function Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# zip([1,2,3],['a','b','c'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format second subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax2.scatter(X[y == t,0],\n",
      "                X[y == t,2],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax2.set_xlabel(Names[0], fontsize=8)\n",
      "    ax2.set_ylabel(Names[2], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format third subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax3.scatter(X[y == t,0],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax3.set_xlabel(Names[0], fontsize=8)\n",
      "    ax3.set_ylabel(Names[3], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format fourth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax4.scatter(X[y == t,1],\n",
      "                X[y == t,2],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax4.set_xlabel(Names[1], fontsize=8)\n",
      "    ax4.set_ylabel(Names[2], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format fifth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax5.scatter(X[y == t,1],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax5.set_xlabel(Names[1], fontsize=8)\n",
      "    ax5.set_ylabel(Names[3], fontsize=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot and format sixth subplot. We could make this a loop, but doing it manually for each\n",
      "#  is more readable for learning purposes.\n",
      "\n",
      "for t,marker,c in zip(xrange(3),\">ox\",\"rgb\") :\n",
      "    ax6.scatter(X[y == t,2],\n",
      "                X[y == t,3],\n",
      "                marker=marker,\n",
      "                c=c)\n",
      "    ax6.set_xlabel(Names[2], fontsize=8)\n",
      "    ax6.set_ylabel(Names[3], fontsize=8)\n",
      "\n",
      "# Save our figure with subplots as one file\n",
      "# plt.savefig('iris_plot_combined.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. KNN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's re-assign the data to standard named variables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = iris.data\n",
      "y = iris.target\n",
      "Names = iris.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split the data into training set and test set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# is there a function to do that in sklearn?\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train KNN classifier defined function on the train data\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn = KNeighborsClassifier(3).fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myknn.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise #1\n",
      "### How does the model perform when you increase the number of neighbors?  \n",
      "\n",
      "###How much do the scores vary each time you shuffle and split?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "test_sizes = []\n",
      "scores = []\n",
      "\n",
      "for i in xrange(99):\n",
      "    s = random.uniform(0.1, 0.9)\n",
      "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=s)\n",
      "    myknn = KNeighborsClassifier(3).fit(X_train,y_train)\n",
      "    test_sizes.append(s)\n",
      "    scores.append(myknn.score(X_test, y_test))\n",
      "                  \n",
      "plt.scatter(test_sizes, scores)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Simplest way to do Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
      "\n",
      "n_samples = len(y)\n",
      "knn = KNeighborsClassifier(3)\n",
      "cv = ShuffleSplit(n_samples, n_iter=10, test_size=0.3, random_state=0)\n",
      "\n",
      "test_scores = cross_val_score(knn, X, y, cv=cv)\n",
      "test_scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 86,
       "text": [
        "0.9622222222222222"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise #2\n",
      "### Calculate the cross-validation score for test_sizes of .1 and .9\n",
      "### How does the model perform at the different test sizes?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### KFolds Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generic cross validation function\n",
      "def cross_validate(X, y, classifier, k_fold) :\n",
      "\n",
      "    # derive a set of (random) training and testing indices\n",
      "    k_fold_indices = KFold( len(X), n_folds=k_fold,\n",
      "                           indices=True, shuffle=True,\n",
      "                           random_state=0)\n",
      "    \n",
      "    k_score_total = 0\n",
      "    \n",
      "    print type(k_fold_indices)\n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "\n",
      "        model = classifier(X[ train_slice  ],\n",
      "                         y[ train_slice  ])\n",
      "\n",
      "        k_score = model.score(X[ test_slice ],\n",
      "                              y[ test_slice ])\n",
      "\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    return k_score_total/k_fold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_validate(X, y, KNeighborsClassifier(3).fit, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'sklearn.cross_validation.KFold'>\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:65: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
        "  stacklevel=1)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "0.95999999999999996"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Enumerate Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x,y in enumerate(['a','b','c']):\n",
      "    print x, \"   \",y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     a\n",
        "1     b\n",
        "2     c\n"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Another way to do Cross Validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "cv = ShuffleSplit(n_samples, n_iter=3, test_size=0.1)\n",
      "\n",
      "for cv_index, (train, test) in enumerate(cv):\n",
      "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
      "    print(\"train indices: {0}...\".format(train[:10]))\n",
      "    print(\"test indices: {0}...\".format(test[:10]))\n",
      "    \n",
      "    myknn = KNeighborsClassifier(3).fit(X[train], y[train])\n",
      "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
      "        myknn.score(X[train], y[train]), myknn.score(X[test], y[test])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# Cross Validation Iteration #0\n",
        "train indices: [ 60  81  55  98 144  35 111  29 124 146]...\n",
        "test indices: [ 69  21  93  63  90 148  64  50  73 123]...\n",
        "train score: 0.970, test score: 0.933\n",
        "\n",
        "# Cross Validation Iteration #1\n",
        "train indices: [111  68 146 101  26 140  88 141  51  80]...\n",
        "test indices: [ 58 100  74 130 119  73 139  91   3  41]...\n",
        "train score: 0.978, test score: 0.867\n",
        "\n",
        "# Cross Validation Iteration #2\n",
        "train indices: [107  92 124   6 144   3 122  79 146 140]...\n",
        "test indices: [100  24 121  25 132  55  20   0 103  98]...\n",
        "train score: 0.956, test score: 1.000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}